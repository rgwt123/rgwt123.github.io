---
layout:     post			    # 使用的布局（不需要改）
title:      面试题基础 				# 标题 
subtitle:   面试
date:       2020-07-20			# 时间
author:     Tao				# 作者
header-img: img/post-bg-universe.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 算法
---

### 编程
- 实现kmeans、KNN
- 从一个素数到另一个素数有几种方式？
- 前缀树实现（精确、模糊匹配）
- 地图中找出大陆的个数（一道BFS题）
- 二叉树最大深度
- 如何判断链表是否有环
- topK小，第K大。怎么最快的找到一堆大数组里面第10大的数。n个数字的流（只能看一次），求前k大（O（N））

### 数学相关
- （1）贝叶斯计算概率？
- （2）25只兔子赛跑问题，共5个赛道，最少几次比赛可以选出前5名？
- （3）100盏灯问题？
- x, y服从0-1均匀分布，求x+y<1的概率？x, y, z服从0-1均匀分布，求x+y+z<1的概率？
- （5）x, y是独立的随机变量，方差期望已知，那么如何求 xy 的方差
- （6）矩阵乘法怎么优化？
- （7）两个上三角矩阵相乘如何优化？
- 什么是半正定矩阵？机器学习中有什么应用？


### 机器学习
#### 基础
- 1.LR、SVM、最大熵、决策树
- 2.SVM原理，与感知机的区别
- HMM 的假设？解决了什么问题？HMM中的矩阵意义？
- 4.CRF的假设是什么？解决了什么问题？CRF做特征工程？维特比算法
- 5.CRF和HMM对比，概率表达不同，递推的公式

#### 聚类
- 1.k-means、KNN，其中KNN算法是否可微
- 层次聚类
- LDA、pLSA、LSA

#### 模型集成
- 为什么要做模型集成？
- boosting两种方法，bagging，stacking
- Boosting、Bagging、随机森林
- 4.Xgboost、Adaboost

#### 其它
- PageRank、TextRank
- 主流推荐算法

### 深度学习
#### 基础
- 常用loss函数、公式、适用场景，尤其交叉熵，高频考点
- 2.梯度消失和梯度爆炸 产生原因？如何解决？
- 3.过拟合 产生原因？解决方法
- 4.正向传播和反向传播
- dropout的作用
- L1、L2范数数学公式，及它们的作用
- 7.常见激活函数及优缺点 sigmoid, tanh, ReLU
- SoftMax + CrossEntropy的反向梯度求导
- 怎么解决beam-search局部最优问题？global embedding 怎么做？
- 10.sgd与adam的区别

#### 神经网络
- 卷积的物理意义是什么？傅里叶变换是什么？
CNN在文本中的用法，pooling的作用，有哪些pooling
- 2.RNN/LSTM
（1）基本框架结构、三个门是什么？计算公式，实际使用时LSTM维度如何选？
（2）rnn梯度弥散和爆炸的原因，lstm为什么不会这样
（3）RNN和LSTM对比
（4）LSTM和GRU的区别
- 3.Transformer
Transformer在实际中怎么用，各部分怎么用？
self-attention原理公式和应用、什么情况下要用
K、Q、V分别是啥，如何计算，
- 4.Attention
Attention怎么用？
- 说一下transforemr、LSTM、CNN几个之间的区别？从多个角度进行讲解？
- 6.Bert
结构、网络层数（12或24层）
预训练：训练任务、过程
如何应用（feature-based、fine-tunning）
- 7.ELMo
- 8.fastText
（1）FastText结构，训练预测为什么快？（因为：层次softmax和负采样，具体原理如哈夫曼树如何构建）
（2）如何获得可靠的top k的输出（第一个0.99，第二个0.001这样的概率很不合理）
- ELMo、GPT、Bert对比
- 10.神经网络优化的难点是什么？
- pytorch的代码流程

### NLP相关
#### 向量
- 1.有哪些？如何训练？各有什么优势劣势？对比？
- 2.Word2vec、Glove、fastText
- 3.word2vec如何训练，CBOW和skip-gram结构理解， hierarhical softmax和negative sampling原理、作用。
- 4.word2vec和fastText对比？
注意fastText训练词向量用的是skip-gram模型，做文本分类用的是CBOW模型，分开做对比。
- 5.glove和word2vec、 LSA对比

#### 语言模型
- 1.传统n-gram原理、和Word2vec对比
- 2.神经网络语言模型原理？有哪些神经网络语言模型？
- 3.传统的统计语言模型和神经网络语言模型有什么不同？

#### 多轮对话
- 如何实现，内部状态机如何设计、如何做到可配置、状态学习（learning）

#### 分类任务
- 层级分类、多标签分类

#### 序列标注任务
- 在做NER任务时，lstm后面可以不用加CRF吗？

#### 相似度
- word2vec和tf-idf 相似度计算时的区别？

#### 具体任务场景
- 自动文章摘要抽取时，怎么对一篇文章进行分割？（从序列标注、无监督等角度思考）